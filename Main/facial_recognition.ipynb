{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from imutils.face_utils import FaceAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. pose_predictor is used to get the 68 facial landmarks detection.\n",
    "2. face_encoder is used to get the (128,1) dimension encoding of the image which is passed to it.\n",
    "   It is a pretrained ResNet network model with 29 conv layers. The model is trained on a dataset of about 3 million faces.\n",
    "3. detector is an object of dlib.get_frontal_face_detector() which is used to get the front face from the face image.\n",
    "4. modelFile, configFile are the files for the dnn based cv2 face detection model.\n",
    "   It is a quantized tensorflow model which is based on the Single Shot-Multibox Detector (SSD) and uses ResNet-10 architecture as its backbone. It was introduced post OpenCV 3.3 in its deep neural network module.\n",
    "5. net is the object of the cv2.dnn module that is initialized with the model and config file.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pose_predictor=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "fa = FaceAligner(pose_predictor)\n",
    "\n",
    "face_encoder=dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "modelFile = 'opencv_face_detector_uint8.pb'\n",
    "\n",
    "configFile = 'opencv_face_detector.pbtxt'\n",
    "\n",
    "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=[]\n",
    "name=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7d65d41ee307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlandmark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceAligned\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfaceAligned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfaceAligned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mface_descriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_face_descriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceAligned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_jitters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_descriptor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for im in os.listdir(trainpath):\n",
    "    print(im)\n",
    "    img = cv2.imread(os.path.join(trainpath,im))\n",
    "   \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    frameHeight = img.shape[0]\n",
    "    frameWidth = img.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0, (300, 300), [104, 117,   123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            faceAligned =fa.align(img, gray,dlib.rectangle(x1,y1,x2,y2))\n",
    "            landmark = pose_predictor(faceAligned,dlib.rectangle(0,0,faceAligned.shape[0],faceAligned.shape[1]))\n",
    "            face_descriptor = face_encoder.compute_face_descriptor(faceAligned, landmark, num_jitters=2)\n",
    "            faces.append(face_descriptor)\n",
    "            im = im.split('_')\n",
    "            name.append(im[0]+\"_\"+im[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.array(faces)\n",
    "name = np.array(name)\n",
    "np.save('face_repr.npy', faces)\n",
    "np.save('labels.npy', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.load(\"face_repr.npy\")\n",
    "name = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajay.jpg\n",
      "['ajay_kumar.jpg', 'Antonio_Banderas', 'Ben_Kingsley', 'Adrien_Brody', 'Brad_Garrett', 'Andy_Serkis', 'Alfred_Molina', 'Brendan_Fraser', 'Bradley_Cooper', 'Alan_Alda'] [0.2749846364781512, 0.7356605475858266, 0.7542944954965313, 0.7636067829359392, 0.7641578906067678, 0.7646803863877131, 0.7667155713513225, 0.7870571949613655, 0.7940957565941018, 0.800250047632669]\n",
      "ajay_kumar.jpg\n",
      "['ajay_kumar.jpg', 'Antonio_Banderas', 'Andy_Serkis', 'Ben_Kingsley', 'Alec_Baldwin', 'Brad_Garrett', 'Brendan_Fraser', 'Adam_Brody', 'Ashton_Kutcher', 'Bradley_Cooper'] [0.11046305156011715, 0.714731187686019, 0.7280857876385486, 0.7377160991009825, 0.7537254712458972, 0.7564561019579998, 0.7660290501885487, 0.7671774818053045, 0.7699488787785754, 0.7815716208744328]\n"
     ]
    }
   ],
   "source": [
    "##Testing\n",
    "testpath = \"./Ajaytest\"\n",
    "for im in os.listdir(testpath):\n",
    "    \n",
    "    image = cv2.imread(os.path.join(testpath,im))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    frameHeight = image.shape[0]\n",
    "    frameWidth = image.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    scores=[]\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            faceAligned = fa.align(image, gray,dlib.rectangle(x1,y1,x2,y2))\n",
    "            landmark = pose_predictor(faceAligned,dlib.rectangle(0,0,faceAligned.shape[0],faceAligned.shape[1]))\n",
    "            face_descriptor = face_encoder.compute_face_descriptor(faceAligned, landmark, num_jitters=2)\n",
    "            score = np.linalg.norm(faces - np.array(face_descriptor), axis=1)\n",
    "            scores.append(score)\n",
    "            imatches = np.argsort(score)\n",
    "            score = score[imatches]\n",
    "            print(im)\n",
    "            print(name[imatches][:10].tolist(), score[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
