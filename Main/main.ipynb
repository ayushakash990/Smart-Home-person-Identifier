{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils.face_utils import FaceAligner\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. pose_predictor is used to get the 68 facial landmarks detection.\n",
    "2. face_encoder is used to get the (128,1) dimension encoding of the image which is passed to it.\n",
    "   It is a pretrained ResNet network model with 29 conv layers. The model is trained on a dataset of about 3 million faces.\n",
    "3. detector is an object of dlib.get_frontal_face_detector() which is used to get the front face from the face image.\n",
    "4. modelFile, configFile are the files for the dnn based cv2 face detection model.\n",
    "   It is a quantized tensorflow model which is based on the Single Shot-Multibox Detector (SSD) and uses ResNet-10 architecture as its backbone. It was introduced post OpenCV 3.3 in its deep neural network module.\n",
    "5. net is the object of the cv2.dnn module that is initialized with the model and config file.\n",
    "\n",
    "\"\"\"\n",
    "print('', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_predictor=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "fa = FaceAligner(pose_predictor)\n",
    "\n",
    "face_encoder=dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "modelFile = 'opencv_face_detector_uint8.pb'\n",
    "\n",
    "configFile = 'opencv_face_detector.pbtxt'\n",
    "\n",
    "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    frameHeight = img.shape[0]\n",
    "    frameWidth = img.shape[1]\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0, (300, 300), [104, 117,   123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    frame = img\n",
    "    \n",
    "    for i in range(detections.shape[2]):\n",
    "        \n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        \n",
    "        if confidence > 0.75:\n",
    "           \n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            \n",
    "            faceAligned =fa.align(img, gray,dlib.rectangle(x1,y1,x2,y2))\n",
    "            landmark = pose_predictor(faceAligned,dlib.rectangle(0,0,faceAligned.shape[0],faceAligned.shape[1]))\n",
    "            \n",
    "            for i in range(0, 68):\n",
    "                x = landmark.part(i).x\n",
    "                y = landmark.part(i).y\n",
    "                cv2.circle(faceAligned, (x, y), 1, (255, 255, 255), -1)\n",
    "            face_descriptor = face_encoder.compute_face_descriptor(faceAligned, landmark, num_jitters=2)\n",
    "\n",
    "            \n",
    "            frame = faceAligned\n",
    "            \n",
    "            \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key =  cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
